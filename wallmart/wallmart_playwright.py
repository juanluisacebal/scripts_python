import pandas as pd
from playwright.sync_api import sync_playwright
import time
import os

INPUT_FILE = "model_file_products.xlsx"
OUTPUT_FILE = "scraped_results.csv"

def buscar_y_extraer(context, nombre):
    resultados = []
    pagina = 1
    while True:
        url_busqueda = f"https://www.walmart.com.mx/search?q={nombre.replace(' ', '+')}&page={pagina}&affinityOverride=default"
        print(f"üîç P√°gina {pagina}: {url_busqueda}")
        page = context.new_page()
        page.goto(url_busqueda)
        resolver_captcha_si_aparece(page)

        page.wait_for_timeout(2000)
        if page.locator("text=No se encontraron resultados para").first.is_visible():
            print("üö´ Fin de resultados detectado por mensaje en p√°gina.")
            page.close()
            break
        try:
            print("‚åõ Esperando aparici√≥n de productos visibles (span.w_q67L)...")
            page.wait_for_selector("span.w_q67L", timeout=15000)
        except:
            print("‚ùå No se encontraron resultados visibles tras esperar.")
            page.close()
            break

        productos = page.query_selector_all("span.w_q67L")
        # Guardar screenshot y HTML para depuraci√≥n
        page.screenshot(path=f"screenshot_{nombre.replace(' ', '_')}_page{pagina}.png", full_page=True)
        with open(f"html_dump_{nombre.replace(' ', '_')}_page{pagina}.html", "w", encoding="utf-8") as f:
            f.write(page.content())
        print("üßæ Screenshot y HTML guardados para depuraci√≥n.")
        print(f"üì¶ Productos encontrados: {len(productos)}")

        for i, prod in enumerate(productos):
            contenedor = prod.evaluate_handle("el => el.closest('div[data-item-id]')").as_element()
            if not contenedor:
                print(f"‚ùó No se encontr√≥ contenedor para producto {i}")
                continue
            print(f"‚úÖ Contenedor encontrado para producto {i}")

            # Buscar t√≠tulo de manera robusta
            titulo_elem = contenedor.query_selector("span.w_q67L")
            titulo = titulo_elem.inner_text() if titulo_elem else "Sin t√≠tulo"
            enlace_elem = contenedor.query_selector("a[href*='/ip/']")
            enlace = enlace_elem.get_attribute("href") if enlace_elem else None

            import re
            id_producto = None
            if enlace:
                match = re.search(r'/(\d{11,})[\?/]?', enlace)
                if match:
                    id_producto = match.group(1)
                else:
                    print("‚ö†Ô∏è No se pudo extraer ID num√©rico de la URL.")

            precio_elem = contenedor.query_selector("span:has-text('$')")
            precio = precio_elem.inner_text() if precio_elem else None
            precio_lista_elem = contenedor.query_selector("span:has-text('Costaba')")
            precio_lista = precio_lista_elem.inner_text() if precio_lista_elem else ""

            import re
            def extraer_precio_numerico(texto):
                try:
                    precio_encontrado = re.search(r"\$?\s*([\d.,]+)", texto if texto else "")
                    if precio_encontrado:
                        valor = precio_encontrado.group(1)
                        # Si hay m√°s de un punto, los puntos son separadores de miles y la coma es decimal
                        if valor.count(".") > 1:
                            valor = valor.replace(".", "")
                            valor = valor.replace(",", ".")
                        else:
                            valor = valor.replace(",", "")
                        return float(valor)
                except:
                    pass
                return None

            precio = extraer_precio_numerico(precio)
            precio_lista = extraer_precio_numerico(precio_lista)
            vendedor = "Walmart"  # valor por defecto
            if enlace:
                producto_page = context.new_page()
                try:
                    producto_page.goto("https://www.walmart.com.mx" + enlace, timeout=20000)
                    resolver_captcha_si_aparece(producto_page)
                    producto_page.wait_for_timeout(3000)
                    try:
                        vendedor_elem = producto_page.query_selector("span[data-testid='product-seller-info'] span")
                        if vendedor_elem:
                            vendedor = vendedor_elem.inner_text().strip()
                            print(f"    üè∑Ô∏è Vendedor detallado: {vendedor}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è No se pudo extraer el vendedor con data-testid: {e}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error al obtener vendedor en detalle: {e}")
                finally:
                    producto_page.close()
            img_elem = contenedor.query_selector("img[src*='walmartimages.com']")
            imagen = img_elem.get_attribute("src") if img_elem else None
            if imagen:
                if imagen.startswith("//"):
                    imagen = "https:" + imagen
                elif imagen.startswith("/"):
                    imagen = "https://www.walmart.com.mx" + imagen

            # Guardar miniatura local si es posible
            from urllib.parse import urlparse
            import urllib.request

            imagen_local = None
            if imagen and imagen.startswith("http"):
                img_name = f"img_{nombre.replace(' ', '_')}_{pagina}_{i}.jpg"
                img_path = os.path.join("imgs", img_name)
                os.makedirs("imgs", exist_ok=True)
                try:
                    urllib.request.urlretrieve(imagen, img_path)
                    imagen_local = img_path
                except Exception as e:
                    print(f"‚ö†Ô∏è Error al descargar imagen: {e}")

            print(f"üìù [{i}] T√≠tulo: {titulo}")
            print(f"    üîó Enlace: {enlace}")
            print(f"    üÜî ID producto: {id_producto}")
            print(f"    üí≤ Precio: {precio}")
            print(f"    üí∞ Precio lista: {precio_lista}")
            print(f"    üè∑Ô∏è Vendedor: {vendedor}")
            print(f"    üñºÔ∏è Imagen: {imagen}")

            url_completa = f"https://www.walmart.com.mx{enlace}" if enlace and not enlace.startswith("http") else enlace
            resultados.append((titulo, precio, precio_lista, id_producto, url_completa, vendedor, imagen_local))
            import random
            delay = random.uniform(8, 12)
            print(f"‚è±Ô∏è Esperando {delay:.2f} segundos antes de continuar con el siguiente producto...")
            page.wait_for_timeout(delay * 1000)

        page.close()
        print(f"‚û°Ô∏è Avanzando a la p√°gina {pagina + 1}")
        pagina += 1

    return resultados

def resolver_captcha_si_aparece(page):
    try:
        print("üß™ Verificando presencia de bot√≥n de captcha...")
        button = page.locator("text=Mant√©n presionado")
        if button.is_visible():
            nombre_archivo = f"captcha_detectado_{int(time.time())}"
            page.screenshot(path=f"{nombre_archivo}.png", full_page=True)
            with open(f"{nombre_archivo}.html", "w", encoding="utf-8") as f:
                f.write(page.content())
            print(f"üì∏ Captura y HTML guardados como {nombre_archivo}.png y {nombre_archivo}.html")
            print("ü§ñ Intentando resolver el captcha autom√°ticamente...")

            box = button.bounding_box()
            if box:
                x = box["x"] + box["width"] / 2
                y = box["y"] + box["height"] / 2
                page.mouse.move(x, y)
                page.mouse.down()
                print("üñ±Ô∏è Mouse presionado sobre el bot√≥n")

                for intento in range(20):
                    still_visible = page.locator("text=Mant√©n presionado").is_visible() or page.locator(".px-inner-loading-area").is_visible()
                    if not still_visible:
                        print("‚úÖ CAPTCHA resuelto exitosamente.")
                        break
                    print(f"‚è≥ Manteniendo presionado... intento {intento+1}")
                    page.wait_for_timeout(1000)
                else:
                    raise Exception("CAPTCHA no resuelto tras espera")

                page.mouse.up()
                print("üñ±Ô∏è Mouse soltado")
    except Exception as e:
        print(f"‚ö†Ô∏è Fallo al intentar resolver el CAPTCHA: {e}")
        raise

def main():
    df = pd.read_excel(INPUT_FILE)
    if os.path.exists(OUTPUT_FILE):
        df_out = pd.read_csv(OUTPUT_FILE)
    else:
        df_out = pd.DataFrame(columns=["Producto", "T√≠tulo encontrado", "Precio", "Precio lista", "ID producto", "URL", "Vendedor", "Imagen"])

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False, args=["--disable-blink-features=AutomationControlled"])
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={"width": 1280, "height": 800},
            locale="es-ES",
            java_script_enabled=True
        )
        context.add_init_script("""() => {
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
        }""")
        for _, row in df.iterrows():
            producto = row["Producto"]
            if producto in df_out["Producto"].values:
                print(f"‚úîÔ∏è Ya procesado: {producto}")
                continue

            resultados = buscar_y_extraer(context, producto)
            if resultados:
                for titulo, precio, precio_lista, id_prod, url, vendedor, img in resultados:
                    df_out.loc[len(df_out)] = [producto, titulo, precio, precio_lista, id_prod, url, vendedor, img]
                    print("üìù Registro guardado:")
                    print(f"  Producto original: {producto}")
                    print(f"  T√≠tulo: {titulo}")
                    print(f"  Precio: {precio}")
                    print(f"  Precio lista: {precio_lista}")
                    print(f"  ID producto: {id_prod}")
                    print(f"  URL: {url}")
                    print(f"  Vendedor: {vendedor}")
                    print(f"  Imagen: {img}")
                    print("‚Äî" * 40)
            time.sleep(1)

        context.close()
        browser.close()

    if not os.path.exists("repetidos.csv"):
        df_reps = pd.DataFrame(columns=df_out.columns)
    else:
        df_reps = pd.read_csv("repetidos.csv")

    nuevos = df_out.duplicated(subset=["ID producto", "Vendedor"], keep="first")
    repetidos = df_out[nuevos]
    df_out = df_out[~nuevos]

    if not repetidos.empty:
        df_reps = pd.concat([df_reps, repetidos], ignore_index=True)
        df_reps.to_csv("repetidos.csv", index=False)

    df_out.to_csv(OUTPUT_FILE, index=False)
    print(f"üìä Total de registros insertados: {len(df_out)}")
    print("‚úÖ Scraping completado.")

if __name__ == "__main__":
    main()